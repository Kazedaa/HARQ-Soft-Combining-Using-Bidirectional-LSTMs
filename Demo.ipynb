{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c06d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import komm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = 2\n",
    "NUM_SYMBOLS = 4\n",
    "INPUT_SIZE = 2*NUM_SYMBOLS*8\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 1\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "MOD = \"ask\" # Choose Modulation Technique[\"qam\", \"ask\", \"psk\", \"pam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2afc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MOD == \"qam\":\n",
    "    mod = komm.QAModulation(16)\n",
    "elif MOD == \"ask\":\n",
    "    mod = komm.ASKModulation(16)\n",
    "elif MOD == \"psk\":\n",
    "    mod = komm.PSKModulation(16)\n",
    "elif MOD== \"pam\":\n",
    "    mod = komm.PAModulation(16)\n",
    "\n",
    "awgn = komm.AWGNChannel(snr=10**(SNR / 10),signal_power=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16217e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = 2\n",
    "qam = komm.QAModulation(16)\n",
    "ask = komm.ASKModulation(16)\n",
    "psk = komm.PSKModulation(16)\n",
    "pam = komm.PAModulation(16)\n",
    "awgn = komm.AWGNChannel(snr=10**(snr / 10),signal_power=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 8\n",
    "num_symbols = 4\n",
    "num_messages_train = 2048\n",
    "num_messages_test = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c726063",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bytes = [[random.randint(0,255) for i in range(num_symbols)] for j in range(num_messages_train)]\n",
    "train_bits = [list(map(int,list(''.join(format(byte,'08b') for byte in train_bytes[j]))))for j in range(num_messages_train)]\n",
    "train_signal = [mod.modulate(train_bits[i]) for i in range(num_messages_train)]\n",
    "train_noisy_signal1 = [awgn(train_signal[i]) for i in range(num_messages_train)]\n",
    "train_noisy_signal2 = [awgn(train_signal[i]) for i in range(num_messages_train)]\n",
    "train_received_bits1 = [mod.demodulate(train_noisy_signal1[i]) for i in range(num_messages_train)]\n",
    "train_received_bits2 = [mod.demodulate(train_noisy_signal2[i]) for i in range(num_messages_train)]\n",
    "\n",
    "train_bits = torch.tensor(train_bits,dtype=torch.float32)\n",
    "train_received_bits1 = torch.tensor(train_received_bits1,dtype=torch.float32)\n",
    "train_received_bits2 = torch.tensor(train_received_bits2,dtype=torch.float32)\n",
    "train_data = torch.stack((train_bits,train_received_bits1,train_received_bits2),axis=1)\n",
    "\n",
    "test_bytes = [[random.randint(0,255) for i in range(num_symbols)] for j in range(num_messages_test)]\n",
    "test_bits = [list(map(int,list(''.join(format(byte,'08b') for byte in test_bytes[j]))))for j in range(num_messages_test)]\n",
    "test_signal = [mod.modulate(test_bits[i]) for i in range(num_messages_test)]\n",
    "test_noisy_signal1 = [awgn(test_signal[i]) for i in range(num_messages_test)]\n",
    "test_noisy_signal2 = [awgn(test_signal[i]) for i in range(num_messages_test)]\n",
    "test_received_bits1 = [mod.demodulate(test_noisy_signal1[i]) for i in range(num_messages_test)]\n",
    "test_received_bits2 = [mod.demodulate(test_noisy_signal2[i]) for i in range(num_messages_test)]\n",
    "\n",
    "test_bits = torch.tensor(test_bits,dtype=torch.float32)\n",
    "test_received_bits1 = torch.tensor(test_received_bits1,dtype=torch.float32)\n",
    "test_received_bits2 = torch.tensor(test_received_bits2,dtype=torch.float32)\n",
    "test_data = torch.stack((test_bits,test_received_bits1,test_received_bits2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=batch_size_train, shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size_test, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0830c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2*num_symbols*8\n",
    "hidden_size = 256\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderModel(torch.nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers):\n",
    "        super(AutoencoderModel, self).__init__()\n",
    "        self.hidden_size= hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.bilstm_block1 = torch.nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional = True)\n",
    "        self.dense1 = torch.nn.Linear(2*hidden_size, input_size // 2)\n",
    "        self.dense2 = torch.nn.Linear(hidden_size, input_size // 2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "      \n",
    "        x,_ = self.bilstm_block1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dense1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c45495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoencoderModel(input_size = input_size, hidden_size= hidden_size, num_layers = num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7dbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa1939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BER(pred,target):\n",
    "    size = torch.numel(target)\n",
    "    return torch.sum(pred!=target).item()/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6dd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(batch, criterion, optimizer, model):\n",
    "    \n",
    "    y,x1,x2 = torch.unbind(batch,dim=1) \n",
    "    x = torch.concat([x1,x2], axis =1)\n",
    "    optimizer.zero_grad()        \n",
    "    y_pred = model(x)       \n",
    "    loss = criterion(y_pred, y)\n",
    "    ber = BER(torch.round(y_pred.detach()),y)\n",
    "    loss.backward()  \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(),ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(batch, criterion, model):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        y,x1,x2 = torch.unbind(batch, dim = 1)\n",
    "        x = torch.concat([x1,x2], axis =1)\n",
    "        y_pred = model(x)\n",
    "        ber = BER(torch.round(y_pred.detach()),y)\n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        return loss.item(),ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efeeeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_bers = []\n",
    "test_bers = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_l = 0.0\n",
    "    test_l = 0.0\n",
    "    train_b = 0.0\n",
    "    test_b = 0.0\n",
    "    count  = 0\n",
    "    for train_batch,test_batch in iter(zip(train_dataloader,test_dataloader)):\n",
    "\n",
    "        train_loss,train_ber = train_loop(batch = train_batch,criterion = criterion,optimizer = optimizer,model = model)\n",
    "        test_loss,test_ber = test_loop(batch = test_batch,criterion = criterion,model = model)\n",
    "        \n",
    "        train_l += train_loss\n",
    "        test_l += test_loss\n",
    "        train_b += train_ber\n",
    "        test_b += test_ber\n",
    "        count += 1\n",
    "        \n",
    "    train_losses.append(train_l / count)\n",
    "    test_losses.append(test_l / count)\n",
    "    train_bers.append(train_b / count)\n",
    "    test_bers.append(test_b / count)\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1} : Training Loss : {train_l / count} Training BER : {train_b / count}  Validation Loss : {test_l / count} Validation BER : {test_b / count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89529b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,len(train_losses)+1)], train_losses, label = \"Training Loss\")\n",
    "plt.plot([i for i in range(1,len(test_losses)+1)] , test_losses, label = \"Validation Loss\", color = 'red',marker = 'o')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,len(train_bers)+1)], train_bers, label = \"Training BER\")\n",
    "plt.plot([i for i in range(1,len(test_bers)+1)] , test_bers, label = \"Validation BER\", color = 'red',marker = 'o')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"BER\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5035f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_pred_train = []\n",
    "noise_x1_train = []\n",
    "noise_x2_train = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x in train_dataloader:\n",
    "        y,x1,x2 = torch.unbind(x, dim = 1)\n",
    "        x = torch.concat([x1,x2], axis =1)\n",
    "        y_pred = model(x).round()\n",
    "        noise_pred_train.append(BER(y_pred,y))\n",
    "        noise_x1_train.append(BER(x1,y))\n",
    "        noise_x2_train.append(BER(x2,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984ac63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,len(noise_pred_train)+1)], noise_pred_train, label = \"Predicted Noise\", color = 'red', marker = 'o')\n",
    "plt.plot([i for i in range(1,len(noise_x1_train)+1)] , noise_x1_train, label = \"First Part Noise\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Noise1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678121e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,len(noise_pred_train)+1)], noise_pred_train, label = \"Predicted Noise\", color = 'red', marker = 'o')\n",
    "plt.plot([i for i in range(1,len(noise_x2_train)+1)] , noise_x2_train, label = \"Second Part Noise\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Noise1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4134ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(snr,data_bits,num_messages,mod):\n",
    "    awgn = komm.AWGNChannel(snr=10**(snr / 10),signal_power=5.0)\n",
    "    data_signal = [mod.modulate(data_bits[i]) for i in range(num_messages)]\n",
    "    data_noisy_signal1 = [awgn(data_signal[i]) for i in range(num_messages)]\n",
    "    data_noisy_signal2 = [awgn(data_signal[i]) for i in range(num_messages)]\n",
    "    data_received_bits1 = [mod.demodulate(data_noisy_signal1[i]) for i in range(num_messages)]\n",
    "    data_received_bits2 = [mod.demodulate(data_noisy_signal2[i]) for i in range(num_messages)]\n",
    "\n",
    "    data_bits = torch.tensor(data_bits,dtype=torch.float32)\n",
    "    data_received_bits1 = torch.tensor(data_received_bits1,dtype=torch.float32)\n",
    "    data_received_bits2 = torch.tensor(data_received_bits2,dtype=torch.float32)\n",
    "    return torch.stack((data_bits,data_received_bits1,data_received_bits2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be4751",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    ber_QAM=[]\n",
    "    ber_PAM=[]\n",
    "    ber_ASK=[]\n",
    "    ber_PSK=[]\n",
    "    for snr in np.arange(-4,30,1):\n",
    "        data_QAM=data_gen(snr,train_bits.detach().numpy(),num_messages_train,qam)\n",
    "        data_QAM = torch.unbind(data_QAM,axis = 1)\n",
    "        data_PAM=data_gen(snr,train_bits.detach().numpy(),num_messages_train,pam)\n",
    "        data_PAM = torch.unbind(data_PAM,axis = 1)\n",
    "        data_PSK=data_gen(snr,train_bits.detach().numpy(),num_messages_train,psk)\n",
    "        data_PSK = torch.unbind(data_PSK,axis = 1)\n",
    "        data_ASK=data_gen(snr,train_bits.detach().numpy(),num_messages_train,ask)\n",
    "        data_ASK = torch.unbind(data_ASK,axis = 1)\n",
    "        y_pred_QAM=model(torch.concat([data_QAM[1],data_QAM[2]],axis=1))\n",
    "        y_pred_PAM=model(torch.concat([data_PAM[1],data_PAM[2]],axis=1))\n",
    "        y_pred_PSK=model(torch.concat([data_PSK[1],data_PSK[2]],axis=1))\n",
    "        y_pred_ASK=model(torch.concat([data_ASK[1],data_ASK[2]],axis=1))\n",
    "        ber_PSK.append(BER(torch.round(y_pred_PSK.detach()),data_PSK[0]))\n",
    "        ber_PAM.append(BER(torch.round(y_pred_PAM.detach()),data_PAM[0]))\n",
    "        ber_ASK.append(BER(torch.round(y_pred_ASK.detach()),data_ASK[0]))\n",
    "        ber_QAM.append(BER(torch.round(y_pred_QAM.detach()),data_QAM[0]))\n",
    "\n",
    "plt.plot(np.arange(-4,30,1),ber_QAM,label='QAM',color='red',marker='o')\n",
    "plt.plot(np.arange(-4,30,1),ber_PAM,label=\"PAM\",color='blue',marker='s')\n",
    "plt.plot(np.arange(-4,30,1),ber_ASK,label=\"ASK\",color='green',marker='^')\n",
    "plt.plot(np.arange(-4,30,1),ber_PSK,label=\"PSK\",color='orange',marker='*')\n",
    "plt.yscale('logit')\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"TrainBER\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840fba5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    ber_QAM=[]\n",
    "    ber_PAM=[]\n",
    "    ber_ASK=[]\n",
    "    ber_PSK=[]\n",
    "    for snr in np.arange(-4,30,1):\n",
    "        data_QAM=data_gen(snr,test_bits.detach().numpy(),num_messages_test,qam)\n",
    "        data_QAM = torch.unbind(data_QAM,axis = 1)\n",
    "        data_PAM=data_gen(snr,test_bits.detach().numpy(),num_messages_test,pam)\n",
    "        data_PAM = torch.unbind(data_PAM,axis = 1)\n",
    "        data_PSK=data_gen(snr,test_bits.detach().numpy(),num_messages_test,psk)\n",
    "        data_PSK = torch.unbind(data_PSK,axis = 1)\n",
    "        data_ASK=data_gen(snr,test_bits.detach().numpy(),num_messages_test,ask)\n",
    "        data_ASK = torch.unbind(data_ASK,axis = 1)\n",
    "        y_pred_QAM=model(torch.concat([data_QAM[1],data_QAM[2]],axis=1))\n",
    "        y_pred_PAM=model(torch.concat([data_PAM[1],data_PAM[2]],axis=1))\n",
    "        y_pred_PSK=model(torch.concat([data_PSK[1],data_PSK[2]],axis=1))\n",
    "        y_pred_ASK=model(torch.concat([data_ASK[1],data_ASK[2]],axis=1))\n",
    "        ber_PSK.append(BER(torch.round(y_pred_PSK.detach()),data_PSK[0]))\n",
    "        ber_PAM.append(BER(torch.round(y_pred_PAM.detach()),data_PAM[0]))\n",
    "        ber_ASK.append(BER(torch.round(y_pred_ASK.detach()),data_ASK[0]))\n",
    "        ber_QAM.append(BER(torch.round(y_pred_QAM.detach()),data_QAM[0]))\n",
    "\n",
    "plt.plot(np.arange(-4,30,1),ber_QAM,label='QAM',color='red',marker='o')\n",
    "plt.plot(np.arange(-4,30,1),ber_PAM,label=\"PAM\",color='blue',marker='s')\n",
    "plt.plot(np.arange(-4,30,1),ber_ASK,label=\"ASK\",color='green',marker='^')\n",
    "plt.plot(np.arange(-4,30,1),ber_PSK,label=\"PSK\",color='orange',marker='*')\n",
    "plt.yscale('logit')\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"TestBER\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
